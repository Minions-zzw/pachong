{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from bs4 import BeautifulSoup\n",
    "def download_page(url): \n",
    "    headers = {'User-Agent': 'User-Agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "    req  = requests.get(url, headers=headers)  # 增加headers, 模拟浏览器\n",
    "    encode_content = req.text\n",
    "    if req.encoding == 'ISO-8859-1': #解决中文乱码的终极方法\n",
    "        encodings = requests.utils.get_encodings_from_content(req.text)\n",
    "        if encodings:\n",
    "            encoding = encodings[0]\n",
    "        else:\n",
    "            encoding = req.apparent_encoding\n",
    "\n",
    "        # encode_content = req.content.decode(encoding, 'replace').encode('utf-8', 'replace')\n",
    "        encode_content = req.content.decode(encoding, 'replace') #如果设置为replace，则会用?取代非法字符；\n",
    "        \n",
    "    return encode_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pic_list(url):\n",
    "    html = download_page(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    con = soup.find('ul', class_=\"pic-list2\")\n",
    "    con_list = con.find_all('li', class_ = 'photo-list-padding')\n",
    "    pic_list = []\n",
    "    title_list = []\n",
    "    for i in con_list:\n",
    "        title = i.find('a',class_ = 'pic').find('span').get_text()\n",
    "        href = i.find('a',class_ = 'pic').get('href')\n",
    "        pic_list.append(href)\n",
    "        title_list.append(title)\n",
    "        \n",
    "    next_page = soup.find('div', class_ = 'pagecon').find('a').get('href')\n",
    "    if(next_page != None):\n",
    "        next_page = 'https://desk.zol.com.cn{}'.format(next_page)\n",
    "    return title_list,pic_list,next_page\n",
    "def create_dir(name):\n",
    "   if not os.path.exists(name):\n",
    "       os.makedirs(name)\n",
    "def get_pic(title_list,href_list,page):\n",
    "    for title,href in zip(title_list,href_list):\n",
    "        print('正在下载:{}'.format(title))\n",
    "        pic_list_html = get_pic_album(href)#拿到一个相册所有图片的具体链接\n",
    "        headers = {'User-Agent': 'User-Agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "        create_dir('pic/page{}/{}'.format(str(page),title))\n",
    "        i = 0\n",
    "        for pic_link in pic_list_html :#开始下载\n",
    "            r = requests.get(pic_link, headers=headers)  # 下载图片，之后保存到文件\n",
    "            i = i+1\n",
    "            with open('pic/page{}/{}/{}({}).png'.format(str(page),title,title,str(i)), 'wb') as f:\n",
    "                f.write(r.content)\n",
    "                time.sleep(0.5)   # 休息一下，不要给网站太大压力，避免被封\n",
    "        \n",
    "\n",
    "def get_pic_album(href):\n",
    "    html_list = []\n",
    "    html,href_next = get_pic_one(href)\n",
    "    html_list.append(html)\n",
    "    while href_next != None:\n",
    "        html,href_next = get_pic_one(href_next)\n",
    "        html_list.append(html)\n",
    "        time.sleep(1)\n",
    "    return html_list\n",
    "def get_pic_one(href):#得到单张图片的最终地址\n",
    "    url = \"https://desk.zol.com.cn{}\".format(href)\n",
    "    html = download_page(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    html = soup.find('div', id = 'mouscroll').find('img').get('src')\n",
    "    href_next = soup.find('div', id = 'mouscroll').find('div', class_ = 'photo-next').find('a', id = 'pageNext').get('href')\n",
    "    if(\"javascript:;\" == href_next):\n",
    "        href_next = None\n",
    "    return html,href_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载:一组超美的自然和风光图片 (8张)\n",
      "MainThread正在下载1页\n",
      "正在下载:美丽的自然风光山水景观图 (8张)\n",
      "MainThread正在下载2页\n",
      "正在下载:宁静安逸摄影的图片壁纸 (8张)\n",
      "正在下载:高清山水风景图片壁纸 (8张)\n",
      "正在下载:绝美大山大自然的美图片壁 (8张)\n",
      "正在下载:唯美深秋美景摄影高清图片 (8张)\n",
      "正在下载:绚丽多彩城市夜景图片壁纸 (9张)\n",
      "正在下载:唯美自然山水风景图片壁纸 (8张)\n",
      "正在下载:绝美道路风光图片壁纸3 (9张)\n",
      "正在下载:唯美秋叶背景图片壁纸 (8张)\n",
      "正在下载:绝美道路风光图片壁纸2 (8张)\n",
      "正在下载:海边护眼高清图片壁纸 (10张)\n",
      "正在下载:林间的公路风景图片壁纸2 (8张)\n",
      "正在下载:唯美迷人的海边风光图片壁 (8张)\n",
      "正在下载:林间的公路风景图片壁纸 (7张)\n",
      "正在下载:高清唯美自然风景摄影图片 (10张)\n",
      "正在下载:唯美水乡风景高清图片壁纸 (8张)\n",
      "正在下载:绚丽霞光风景图片壁纸 (9张)\n",
      "正在下载:唯美水乡风景高清图片壁纸 (7张)\n",
      "正在下载:麦田唯美图片壁纸 (8张)\n",
      "正在下载:海边沙滩图片高清壁纸2 (10张)\n",
      "正在下载:丰收的麦子麦穗图片壁纸 (10张)\n",
      "正在下载:好看的瀑布山水风景图片壁 (10张)\n",
      "正在下载:超唯美的雪山风景图片壁纸 (7张)\n",
      "正在下载:高清大海海滩图片壁纸 (9张)\n",
      "正在下载:最美227国道沿途风景图片 (10张)\n",
      "正在下载:欧美小镇特色门窗图片壁纸 (8张)\n",
      "正在下载:青海茶卡盐湖风景高清图片 (13张)\n",
      "正在下载:清新自然剪影风景图片壁纸 (10张)\n",
      "正在下载:祁连卓尔山风景摄影高清图 (11张)\n",
      "正在下载:清新自然剪影风景图片壁纸 (9张)\n",
      "正在下载:中国最美公路227国道沿途 (10张)\n",
      "正在下载:好看的大桥风景图片壁纸 (11张)\n",
      "正在下载:青海卓尔山壮观风景图片壁 (11张)\n",
      "正在下载:绿色清新护眼风景高清图片 (8张)\n",
      "正在下载:美丽自然水域风景图片壁纸 (8张)\n",
      "正在下载:青海祁连卓尔山风景摄影高 (12张)\n",
      "正在下载:绿色森林河流大自然风景俯 (8张)\n",
      "正在下载:唯美星空夜景高清图片壁纸 (9张)\n",
      "正在下载:精选唯美养眼风景图片壁纸 (8张)\n",
      "正在下载:美丽的小镇风景摄影图片壁 (8张)\n",
      "正在下载:一组超美的自然和风光图片 (8张)MainThread正在下载3页\n",
      "\n",
      "正在下载:青海茶卡盐湖唯美图片壁纸 (14张)\n",
      "正在下载:宁静安逸摄影的图片壁纸 (8张)\n",
      "正在下载:绝美大山大自然的美图片壁 (8张)\n",
      "正在下载:绚丽多彩城市夜景图片壁纸 (9张)\n",
      "正在下载:绝美道路风光图片壁纸3 (9张)\n",
      "正在下载:绝美道路风光图片壁纸2 (8张)\n",
      "正在下载:林间的公路风景图片壁纸2 (8张)\n",
      "正在下载:林间的公路风景图片壁纸 (7张)\n",
      "正在下载:唯美水乡风景高清图片壁纸 (8张)\n",
      "正在下载:唯美水乡风景高清图片壁纸 (7张)\n",
      "正在下载:海边沙滩图片高清壁纸2 (10张)\n",
      "正在下载:好看的瀑布山水风景图片壁 (10张)\n",
      "正在下载:高清大海海滩图片壁纸 (9张)\n",
      "正在下载:欧美小镇特色门窗图片壁纸 (8张)\n",
      "正在下载:清新自然剪影风景图片壁纸 (10张)\n",
      "正在下载:清新自然剪影风景图片壁纸 (9张)\n",
      "正在下载:好看的大桥风景图片壁纸 (11张)\n",
      "正在下载:绿色清新护眼风景高清图片 (8张)\n",
      "正在下载:美丽自然水域风景图片壁纸 (8张)\n",
      "正在下载:绿色森林河流大自然风景俯 (8张)\n",
      "正在下载:精选唯美养眼风景图片壁纸 (8张)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #获取1-3页的链接内容\n",
    "    next_page = 'https://desk.zol.com.cn/fengjing/'\n",
    "    title_list_all = [] #存贮所有页所有的相册的地址\n",
    "    pic_list_all = [] #存贮所有页所有的相册的名字\n",
    "    page_all = []#存贮页数\n",
    "    for page in range(1,4):#获取每页中每册相册的地址和名字\n",
    "        title_list,pic_list,next_page = get_pic_list(next_page)\n",
    "        title_list_all.append(title_list)\n",
    "        pic_list_all.append(pic_list)\n",
    "        page_all.append(page)\n",
    "        \n",
    "        if(None == next_page):\n",
    "            break;\n",
    "    threads = []\n",
    "    while len(page_all) > 0:\n",
    "        for thread in threads:#杀掉无用线程\n",
    "            if not thread.is_alive():\n",
    "                threads.remove(thread)\n",
    "        while len(threads) < 2 and len(page_all) > 0:   # 最大线程数设置为 2\n",
    "            title_list = title_list_all.pop(0)\n",
    "            pic_list = pic_list_all.pop(0)\n",
    "            page = page_all.pop(0)\n",
    "            thread = threading.Thread(target=get_pic, args=(title_list,pic_list,page,))\n",
    "            thread.setDaemon(True)\n",
    "            thread.start()\n",
    "            print('{}正在下载{}页'.format(threading.current_thread().name, page))\n",
    "            threads.append(thread)\n",
    "if __name__ == '__main__':\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一组超美的自然和风光图片 (8张)', '宁静安逸摄影的图片壁纸 (8张)', '绝美大山大自然的美图片壁 (8张)', '绚丽多彩城市夜景图片壁纸 (9张)', '绝美道路风光图片壁纸3 (9张)', '绝美道路风光图片壁纸2 (8张)', '林间的公路风景图片壁纸2 (8张)', '林间的公路风景图片壁纸 (7张)', '唯美水乡风景高清图片壁纸 (8张)', '唯美水乡风景高清图片壁纸 (7张)', '海边沙滩图片高清壁纸2 (10张)', '好看的瀑布山水风景图片壁 (10张)', '高清大海海滩图片壁纸 (9张)', '欧美小镇特色门窗图片壁纸 (8张)', '清新自然剪影风景图片壁纸 (10张)', '清新自然剪影风景图片壁纸 (9张)', '好看的大桥风景图片壁纸 (11张)', '绿色清新护眼风景高清图片 (8张)', '美丽自然水域风景图片壁纸 (8张)', '绿色森林河流大自然风景俯 (8张)', '精选唯美养眼风景图片壁纸 (8张)'] ['/bizhi/9611_116395_2.html', '/bizhi/9607_116359_2.html', '/bizhi/9596_116278_2.html', '/bizhi/9595_116269_2.html', '/bizhi/9585_116180_2.html', '/bizhi/9580_116140_2.html', '/bizhi/9574_116074_2.html', '/bizhi/9563_115980_2.html', '/bizhi/9547_115837_2.html', '/bizhi/9545_115816_2.html', '/bizhi/9540_115767_2.html', '/bizhi/9539_115751_2.html', '/bizhi/9536_115730_2.html', '/bizhi/9527_115644_2.html', '/bizhi/9522_115594_2.html', '/bizhi/9518_115552_2.html', '/bizhi/9506_115438_2.html', '/bizhi/9499_115390_2.html', '/bizhi/9495_115357_2.html', '/bizhi/9494_115353_2.html', '/bizhi/9488_115287_2.html'] /fengjing/2.html\n"
     ]
    }
   ],
   "source": [
    "title_list,pic_list,next_page = get_pic_list('https://desk.zol.com.cn/fengjing/',1)\n",
    "print(title_list,pic_list,next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fengjing/2.html\n"
     ]
    }
   ],
   "source": [
    "print(next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def download_page(url):\n",
    "   '''\n",
    "   用于下载页面\n",
    "   '''\n",
    "   headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0\"}\n",
    "   r = requests.get(url, headers=headers)\n",
    "   r.encoding = 'gb2312'\n",
    "   return r.text\n",
    "\n",
    "\n",
    "def get_pic_list(html):\n",
    "   '''\n",
    "   获取每个页面的套图列表,之后循环调用get_pic函数获取图片\n",
    "   '''\n",
    "   soup = BeautifulSoup(html, 'html.parser')\n",
    "   pic_list = soup.find_all('li', class_='wp-item')\n",
    "   for i in pic_list:\n",
    "       a_tag = i.find('h3', class_='tit').find('a')\n",
    "       link = a_tag.get('href')\n",
    "       text = a_tag.get_text()\n",
    "       get_pic(link, text)\n",
    "\n",
    "\n",
    "def get_pic(link, text):\n",
    "   '''\n",
    "   获取当前页面的图片,并保存\n",
    "   '''\n",
    "   html = download_page(link)  # 下载界面\n",
    "   soup = BeautifulSoup(html, 'html.parser')\n",
    "   pic_list = soup.find('div', id=\"picture\").find_all('img')  # 找到界面所有图片\n",
    "   headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0\"}\n",
    "   create_dir('pic/{}'.format(text))\n",
    "   for i in pic_list:\n",
    "       pic_link = i.get('src')  # 拿到图片的具体 url\n",
    "       r = requests.get(pic_link, headers=headers)  # 下载图片，之后保存到文件\n",
    "       with open('pic/{}/{}'.format(text, link.split('/')[-1]), 'wb') as f:\n",
    "           f.write(r.content)\n",
    "           time.sleep(1)   # 休息一下，不要给网站太大压力，避免被封\n",
    "\n",
    "\n",
    "def create_dir(name):\n",
    "   if not os.path.exists(name):\n",
    "       os.makedirs(name)\n",
    "\n",
    "\n",
    "def execute(url):\n",
    "   page_html = download_page(url)\n",
    "   get_pic_list(page_html)\n",
    "\n",
    "\n",
    "def main():\n",
    "   create_dir('pic')\n",
    "   queue = [i for i in range(1, 72)]   # 构造 url 链接 页码。\n",
    "   threads = []\n",
    "   while len(queue) > 0:\n",
    "       for thread in threads:\n",
    "           if not thread.is_alive():\n",
    "               threads.remove(thread)\n",
    "       while len(threads) < 5 and len(queue) > 0:   # 最大线程数设置为 5\n",
    "           cur_page = queue.pop(0)\n",
    "           url = 'http://meizitu.com/a/more_{}.html'.format(cur_page)\n",
    "           thread = threading.Thread(target=execute, args=(url,))\n",
    "           thread.setDaemon(True)\n",
    "           thread.start()\n",
    "           print('{}正在下载{}页'.format(threading.current_thread().name, cur_page))\n",
    "           threads.append(thread)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
