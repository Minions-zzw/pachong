{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from bs4 import BeautifulSoup\n",
    "from verification import Identification_verification\n",
    "from verification import ResNet\n",
    "from verification import ResidualBlock\n",
    "import json\n",
    "import re\n",
    "import cv2#识别验证码模块\n",
    "import os\n",
    "import execjs\n",
    "# OKOK\n",
    "#FINE\n",
    "def download_page(url): \n",
    "    headers = {'Connection': 'keep-alive',\n",
    "        'User-Agent': 'User-Agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "    req  = requests.get(url, headers=headers)  # 增加headers, 模拟浏览器\n",
    "    encode_content = req.text\n",
    "    if req.encoding == 'ISO-8859-1': #解决中文乱码的终极方法\n",
    "        encodings = requests.utils.get_encodings_from_content(req.text)\n",
    "        if encodings:\n",
    "            encoding = encodings[0]\n",
    "        else:\n",
    "            encoding = req.apparent_encoding\n",
    "\n",
    "        # encode_content = req.content.decode(encoding, 'replace').encode('utf-8', 'replace')\n",
    "        encode_content = req.content.decode(encoding, 'replace') #如果设置为replace，则会用?取代非法字符；\n",
    "        \n",
    "    return encode_content\n",
    "def find_werzhi(i):\n",
    "    return -1 != str(i).find('selected')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "def excel_to_matrix(path): #读取excel的函数\n",
    "    data = xlrd.open_workbook(path)\n",
    "    table = data.sheets()[0] \n",
    "    nrows = table.nrows\n",
    "    data_usr_pas = []\n",
    "    for row in range(nrows):\n",
    "        data_usr_pas.append(table.row_values(row))\n",
    "    data_usr_pas.pop(0)\n",
    "    return data_usr_pas\n",
    "def shangbao(datas): #签到主流程\n",
    "    for data in datas:\n",
    "        url = \"https://jksb.v.zzu.edu.cn\"\n",
    "        login_url = 'https://jksb.v.zzu.edu.cn/vls6sss/zzujksb.dll/login'\n",
    "        headers = {'User-agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}\n",
    "        html = download_page(url)\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        frame_url = soup.find('div', id = 'mt_2').find('iframe').get('src') #找到表格的地址\n",
    "        html = download_page(frame_url)\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        yanzheng = soup.find_all('div', class_ = 'mt_3b')\n",
    "        m = 0\n",
    "        if \"验证码\" == yanzheng[2].get_text(): #有验证码时候的处理\n",
    "            while(1):\n",
    "\n",
    "                html = download_page(url)\n",
    "                script_code = \"\"\"\n",
    "                function zzjfun1109a()\n",
    "                  {\n",
    "                    var s127=Math.round(Math.random()*10000);\n",
    "                    src=\"https://jksb.v.zzu.edu.cn/vls6sss/zzjlogin3d.dll/zzjgetimg?ids=\"+s127;\n",
    "                    return src\n",
    "                  }\n",
    "                \"\"\"\n",
    "                js = execjs.compile(script_code)\n",
    "                url = js.call('zzjfun1109a')\n",
    "\n",
    "                soup2 = BeautifulSoup(html,'html.parser')\n",
    "                #生成验证码网址\n",
    "\n",
    "                js = execjs.compile(script_code)\n",
    "                verification_url = js.call('zzjfun1109a')\n",
    "                #获得验证码网址\n",
    "                r = requests.get('https://jksb.v.zzu.edu.cn/vls6sss/zzjlogin3d.dll/zzjgetimg?ids=8778', headers=headers)  # 下载图片，之后保存到文件\n",
    "                with open('H:\\Code\\shizhan\\pachong\\data\\123.png', 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "\n",
    "                img = cv2.imread('H:\\Code\\shizhan\\pachong\\data\\123.png')\n",
    "                verification_text = Identification_verification(img)\n",
    "                os.remove('H:\\Code\\shizhan\\pachong\\data\\123.png')\n",
    "\n",
    "                data['ver6'] = verification_text #更改要提交的数据\n",
    "\n",
    "                headers = {'User-agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}\n",
    "                session = requests.Session()\n",
    "                response = session.post(login_url, data=data, headers=headers)  # 获取此次文本\n",
    "                response.encoding = response.apparent_encoding #转码\n",
    "                soup = BeautifulSoup(response.text, 'html.parser') #转换成bf\n",
    "                a1 = soup.find(\"title\").get_text()\n",
    "                print(\"识别验证码：\")\n",
    "                if a1.find(\"郑州\") >= 0 :\n",
    "                    b1 = soup.find(\"div\", id=\"bak_0\").get_text()\n",
    "                    if b1.find(\"验证码\") >= 0 :\n",
    "                        print(\"验证码错误，尝试重新登录。\")\n",
    "                        m = m+1\n",
    "                        time.sleep(1)\n",
    "                        if m > 20:\n",
    "                            break\n",
    "                        continue;\n",
    "                print(\"验证码识别成功。\")\n",
    "                break;\n",
    "        else:#无验证码时候的处理\n",
    "            session = requests.Session()\n",
    "            response = session.post(login_url, data=data, headers=headers)  # 获取此次文本\n",
    "            response.encoding = response.apparent_encoding #转码\n",
    "            soup = BeautifulSoup(response.text, 'html.parser') #转换成bf\n",
    "        \n",
    "        str_pat = re.compile(r'\"(.*)\"') #设置正则表达式搜索用于页面网址\n",
    "        text_list = str_pat.findall(str(soup.find('script')))#找到所有双引号的内容\n",
    "        url = max(text_list, key=len, default='') #得到链表中最长的元素，也就是url\n",
    "        \n",
    "        if 0 >= url.count('https'):\n",
    "            print('学号：{}密码错误，跳过此学号'.format(data['uid']))\n",
    "            continue;\n",
    "        \n",
    "        print(url)\n",
    "        time.sleep(1)\n",
    "        html = download_page(url) #下载下一个页面\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        frame_url = soup.find('iframe', id = 'zzj_top_6s').get('src') #找到表格的地址\n",
    "        time.sleep(1)\n",
    "        html = download_page(frame_url)\n",
    "        soup = BeautifulSoup(html,'html.parser') \n",
    "        con = soup.find('div', id = 'bak_0')\n",
    "        con_list = con.find_all('input')#找到要提交的几个value参数\n",
    "        value_list = [i.get('value') for i in con_list]\n",
    "        print(value_list)\n",
    "        tianbao_url = \"https://jksb.v.zzu.edu.cn/vls6sss/zzujksb.dll/jksb\"\n",
    "        data = {\n",
    "            'day6' : value_list[0],\n",
    "            'did': value_list[1],\n",
    "            'door': value_list[2],\n",
    "            'men6': value_list[3],\n",
    "            'ptopid': value_list[4],\n",
    "            'sid':value_list[5],\n",
    "        }\n",
    "        time.sleep(1)\n",
    "        response = session.post(tianbao_url, data=data, headers=headers)  # 获取此次文本\n",
    "        response.encoding = response.apparent_encoding #转码\n",
    "        soup = BeautifulSoup(response.text, 'html.parser') #转换成bf\n",
    "        input_list = soup.find_all('input')\n",
    "        weizhi_a = soup.find('select', id='myvs_13a').find_all('option')\n",
    "        weizhi_b = soup.find('select', id='myvs_13b').find_all('option')\n",
    "        werzhi_a_selected = list(filter(find_werzhi,weizhi_a))[0].get('value')\n",
    "        werzhi_b_selected = list(filter(find_werzhi,weizhi_b))[0].get('value')\n",
    "        if_at_school = '在校'\n",
    "        data = { #构建要提交的表单\n",
    "            'myvs_1': '否','myvs_2': '否','myvs_3': '否', 'myvs_4': '否','myvs_5': '否','myvs_6': '否','myvs_7': '否','myvs_8': '否','myvs_9': '否','myvs_10': '否','myvs_11': '否','myvs_12': '否',\n",
    "            'myvs_13a': werzhi_a_selected,\n",
    "            'myvs_13b': werzhi_b_selected,\n",
    "            'myvs_13c': input_list[25].get('value'),\n",
    "            'myvs_14': input_list[27].get('value'),\n",
    "            'myvs_14b': input_list[28].get('value'),\n",
    "            'myvs_30': if_at_school,\n",
    "            'memo22': input_list[29].get('value'),\n",
    "            'did': input_list[30].get('value'),\n",
    "            'door': input_list[31].get('value'),\n",
    "            'day6': input_list[32].get('value'),\n",
    "            'men6': input_list[33].get('value'),\n",
    "            'sheng6': input_list[34].get('value'),\n",
    "            'shi6': input_list[35].get('value'),\n",
    "            'fun3': input_list[36].get('value'),\n",
    "            'jingdu': input_list[37].get('value'),\n",
    "            'werdu': input_list[38].get('value'),\n",
    "            'ptopid': input_list[39].get('value'),\n",
    "            'std': input_list[40].get('value')\n",
    "        }\n",
    "        print(data)\n",
    "        time.sleep(1)\n",
    "        post_url = 'https://jksb.v.zzu.edu.cn/vls6sss/zzujksb.dll/jksb'\n",
    "        response = session.post(tianbao_url, data=data, headers=headers)  # 进行健康签到\n",
    "        response.encoding = response.apparent_encoding #转码\n",
    "        soup = BeautifulSoup(response.text, 'html.parser') #转换成bf\n",
    "        con = soup.find('div', style='width:296px;height:100%;font-size:14px;color:#333;line-height:26px;float:left;').get_text() #提取返回信息\n",
    "        print(con)\n",
    "def create_dir(name):\n",
    "    if not os.path.exists(name):\n",
    "        os.makedirs(name)\n",
    "def main(): #开始签到\n",
    "    data = excel_to_matrix('H:\\Code\\shizhan\\pachong\\data\\data.xlsx') #用于读取文件\n",
    "    datas = []\n",
    "    for i in range(len(data)):\n",
    "        data_one = {\n",
    "            'uid': data[i][1],\n",
    "            'upw': data[i][2],\n",
    "            'smbtn': '进入健康状况上报平台',\n",
    "            'ver6': '',\n",
    "            'hh28': 540\n",
    "        }\n",
    "        datas.append(data_one)\n",
    "    print(datas)\n",
    "    create_dir('H:\\\\Code\\\\shizhan\\\\pachong\\\\test-wenjianjia')\n",
    "    shangbao(datas)\n",
    "    os.system(\"pause\")\n",
    "    time.sleep(5)\n",
    "    os.system(\"pause\")\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
