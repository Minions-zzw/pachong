{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.utils.data as tud\n",
    "import pdb\n",
    "import random\n",
    "import struct\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(img):\n",
    "    for i in range(15):\n",
    "        img[0][i] = 255\n",
    "        img[24][i] = 255\n",
    "    for i in range(25):\n",
    "        img[i][0] = 255\n",
    "        img[i][14] = 255\n",
    "    for x in range(23):\n",
    "        x = x+1\n",
    "        for y in range(13):\n",
    "            y = y+1\n",
    "            m = 0\n",
    "            if(0 == img[x-1][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x-1][y]):\n",
    "                m = m+1\n",
    "            if(0 == img[x-1][y+1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x][y+1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y+1]):\n",
    "                m = m+1\n",
    "            if m<3:\n",
    "                img[x][y] = 255\n",
    "    for x in range(23-1,-1,-1):\n",
    "        x = x+1\n",
    "        for y in range(13-1,-1,-1):\n",
    "            y = y+1\n",
    "            m = 0\n",
    "            if(0 == img[x-1][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x-1][y]):\n",
    "                m = m+1\n",
    "            if(0 == img[x-1][y+1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x][y+1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y+1]):\n",
    "                m = m+1\n",
    "            if m<3:\n",
    "                img[x][y] = 255\n",
    "    return img\n",
    "def threshold_demo(image):#二值化函数\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) #把输入图像灰度化\n",
    "    #直接阈值化是对输入的单通道矩阵逐像素进行阈值分割。\n",
    "    ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_TRIANGLE)\n",
    "#     print(\"threshold value %s\"%ret)\n",
    "    return binary\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "#resnet 网络结构\n",
    "import torch as t\n",
    " \n",
    "class ResidualBlock(nn.Module): \n",
    "    #实现子module: Residual    Block\n",
    "    def __init__(self,inchannel,outchannel,stride=1,shortcut=None):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.left=nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,3,stride,1,bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel,outchannel,3,1,1,bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        \n",
    "        self.right=shortcut\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.left(x)\n",
    "        residual=x if self.right is None else self.right(x)\n",
    "        out+=residual\n",
    "        return F.relu(out)\n",
    "    \n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    #实现主module:ResNet34\n",
    "    #ResNet34包含多个layer,每个layer又包含多个residual block\n",
    "    #用子module实现residual block , 用 _make_layer 函数实现layer\n",
    "    def __init__(self,num_classes=1000):\n",
    "        super(ResNet,self).__init__()\n",
    "        #重复的layer,分别有3,4,6,3个residual block\n",
    "        self.BN = nn.BatchNorm2d(1)\n",
    "#         48-3+1 = 46\n",
    "#         (46-3-1)/2 = 21\n",
    "#         (21-5-1)/2 = 21\n",
    "# torch.Size([64, 64, 25, 25])\n",
    "# torch.Size([64, 128, 13, 13])\n",
    "# torch.Size([64, 256, 7, 7])\n",
    "# torch.Size([64, 512, 4, 4])\n",
    "#         25-2+1 = 24\n",
    "#         (24-2)/2+1\n",
    "        self.layer1=self._make_layer(1,64,2)\n",
    "        self.layer2=self._make_layer(64,128,3,)\n",
    "        self.layer3=self._make_layer(128,256,2,stride=2)\n",
    "        self.layer4=self._make_layer(256,512,2,stride=2)\n",
    "        \n",
    "        #分类用的全连接\n",
    "        self.fc=nn.Linear(512,num_classes)\n",
    "        \n",
    "    def _make_layer(self,inchannel,outchannel,block_num,stride=1):\n",
    "        #构建layer,包含多个residual block\n",
    "        shortcut=nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,1,stride,bias=False),\n",
    "            nn.BatchNorm2d(outchannel))\n",
    " \n",
    "        layers=[ ]\n",
    "        layers.append(ResidualBlock(inchannel,outchannel,stride,shortcut))\n",
    "        \n",
    "        for i in range(1,block_num):\n",
    "            layers.append(ResidualBlock(outchannel,outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.BN(x)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=F.avg_pool2d(x,7)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# def find_file_name(file_dir):#获取文件夹下所有文件名\n",
    "#     for root, dirs, files in os.walk(file_dir):\n",
    "#         return files\n",
    "# files_name = find_file_name('data')\n",
    "\n",
    "\n",
    "# for n in range(300):\n",
    "#     img = cv2.imread('data/'+files_name[n])\n",
    "#     for i in range(4):\n",
    "#         cropped = img[0:25, 15*(i):15*(i+1)]  # 裁剪坐标为[y0:y1, x0:x1]\n",
    "#         cv2.imwrite(\"data/one/\"+str(n)+\"_\"+str(i)+\"_\"+str(files_name[n][i])+\".jpg\", cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionClassificationDataset(tud.Dataset): #定义数据读取类，此类用于读取数据，最为关键的函数是getitem（）\n",
    "    def __init__(self,training_image): #此函数用于初始化\n",
    "        super(ExpressionClassificationDataset, self).__init__()\n",
    "        self.training_data = training_image.to(DEVICE)\n",
    "        \n",
    "    def __len__(self): #此函数用于确定总数据大小，用于生成所有的bitch\n",
    "        return len(self.training_data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.training_data[idx]/255.; #/255是把数据的大小限制在0-1之间，能极大减少学习的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(img):#数据处理函数\n",
    "    datas = []\n",
    "    for i in range(4):\n",
    "        cropped = img[0:25, 15*(i):15*(i+1)]  # 裁剪坐标为[y0:y1, x0:x1]\n",
    "        datas.append(cropped)\n",
    "    add = [255 for i in range(125)] #用于拼接的矩阵，把剪切出来的图片拼接成正方形的图形\n",
    "    add = np.array(add)\n",
    "    add = add.reshape(25,5)\n",
    "    data_image = [[np.c_[add,judge(threshold_demo(n)),add]] for n in datas]#生成二值化之后的数据#其中做了judge，去噪，拼接矩阵#这一行非常复杂，需要理解很久\n",
    "    datas = np.array(data_image) #datas的类型从list转换为numpy\n",
    "    datas = datas.astype(np.float32) #把atas里面数据强转为float32\n",
    "    verification_image = torch.from_numpy(datas) #把datas变成torch类型的矩阵(torch可以使用gpu)\n",
    "    return verification_image\n",
    "def forecast(verification_image):\n",
    "    dataset = ExpressionClassificationDataset(verification_image)#放入数据处理函数，可用于不同设备的计算，用于生成batch\n",
    "    dataloader = tud.DataLoader(dataset, batch_size=4) #生成bitch\n",
    "    if torch.device(\"cpu\") == DEVICE:\n",
    "        model = torch.load(\"H:\\Code\\验证码识别\\model.pth\",map_location='cpu') #读取模型\n",
    "    else:\n",
    "        model = torch.load(\"H:\\Code\\验证码识别\\model.pth\") #读取模型\n",
    "        \n",
    "    for i,x in enumerate (dataloader):\n",
    "        y_pred = model.forward(x)  #前项传播\n",
    "    verification_lable = [torch.argmax(i) for i in y_pred]#根据预测得出预测标签\n",
    "    ind = \"123456789abcdefghijklmnopqrstuvwxyz\" #用于生成最终预测字符\n",
    "    verification_letter = [ind[n.item()] for n in verification_lable]#转换成数字标签\n",
    "    verification_text = ''.join(verification_letter) #字符list转换为字符串\n",
    "    return verification_text\n",
    "\n",
    "def Identification_verification(img = None, PATH = None):\n",
    "    if img is None and None == PATH:\n",
    "        return \"错误：无数据传入\"\n",
    "    if None != PATH:\n",
    "        img = cv2.imread(PATH)\n",
    "    verification_image = data_processing(img)\n",
    "    verification_text = forecast(verification_image)\n",
    "    \n",
    "    return verification_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6d8j\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"data/6d8j_300.png\")\n",
    "verification_text = Identification_verification(img = img)\n",
    "print(verification_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_name(file_dir):#获取文件夹下所有文件名\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzjgetimg (1).png:2y2v\n",
      "zzjgetimg (10).png:riqm\n",
      "zzjgetimg (2).png:a6ex\n",
      "zzjgetimg (3).png:nwyn\n",
      "zzjgetimg (4).png:7z4b\n",
      "zzjgetimg (5).png:nd7g\n",
      "zzjgetimg (6).png:2yz7\n",
      "zzjgetimg (8).png:an2y\n",
      "zzjgetimg (9).png:eyk9\n"
     ]
    }
   ],
   "source": [
    "files_name = find_file_name('data/ceshi')#获取所有文件名\n",
    "for file in files_name:\n",
    "    print(file +\":\"+ Identification_verification(PATH = \"data/ceshi/\"+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('data/ceshi/zzjgetimg (1).png')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 25])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a = training_image[3][0].reshape(25,25) #显示图片\n",
    "fig = plt.figure()\n",
    "plotwindow = fig.add_subplot(111)\n",
    "plt.imshow(a , cmap='gray')\n",
    "plt.show()\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
