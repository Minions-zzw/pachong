{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvly\n",
      "b\n",
      "9\n",
      "35\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# vocab.py #用于管理验证码词汇\n",
    "import random\n",
    "import numpy as np\n",
    "'''\n",
    "    A default vocab implementation and base class, to provide random letters and numbers.\n",
    "'''\n",
    "class Vocab():\n",
    "    def __init__(self):\n",
    "        self.vocab = \"123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "        self.size = len(self.vocab)\n",
    "        indices = range(self.size)\n",
    "        self.index = dict(zip(self.vocab, indices))\n",
    "    # return random string by given length\n",
    "    def rand_string(self, length):\n",
    "        # if len(vocab) == 0 raise exception\n",
    "        return \"\".join(random.sample(self.vocab, length))\n",
    "    # get symbol (char in vocabulary) by its ordinal\n",
    "    def get_sym(self, idx):\n",
    "        # if idx >= len(self.vocab) raise exception\n",
    "        return self.vocab[idx]\n",
    "    # given a symbol, return its ordinal in given vocabulary.\n",
    "    def get_index(self, sym):\n",
    "        return self.index[sym]\n",
    "    # given 'abc', return [10, 11, 12]\n",
    "    def to_indices(self, text):\n",
    "        return [self.index[c] for c in text]\n",
    "    # given [10, 11, 12], return 'abc'\n",
    "    def to_text(self, indices):\n",
    "        return \"\".join([self.vocab[i] for i in indices])\n",
    "    # given '01', return vector [1 0 0 0 0 0 0 0 0 0 ... 0 \\n 0 1 0 0 0 0 ... 0]\n",
    "    def text_to_one_hot(self, text):\n",
    "        num_labels = np.array(self.to_indices(text))\n",
    "        n = len(text)\n",
    "        categorical = np.zeros((n, self.size))\n",
    "        categorical[np.arange(n), num_labels] = 1\n",
    "        return categorical.ravel()\n",
    "    # translate one hot vector to text.\n",
    "    def one_hot_to_text(self, onehots):\n",
    "        text_len = onehots.shape[0] // self.size\n",
    "        onehots = np.reshape(onehots, (text_len, self.size))\n",
    "        indices = np.argmax(onehots, axis = 1)\n",
    "        return self.to_text(indices)\n",
    "if __name__ == \"__main__\":\n",
    "    # test code\n",
    "    vocab = Vocab()\n",
    "    print(vocab.rand_string(4))\n",
    "    print(vocab.get_sym(10))\n",
    "    print(vocab.get_index('a'))\n",
    "    print(vocab.size)\n",
    "    print(vocab.text_to_one_hot(\"abc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xid7\n"
     ]
    }
   ],
   "source": [
    "# PIL是一个常用的python图像库。在python 3.5中， 应该使用pip install pillow来安装\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageFilter\n",
    "import random\n",
    "from vocab import Vocab\n",
    "class Captcha:\n",
    "    '''\n",
    "    size: width, height in pixel\n",
    "    font: font family(string), size (unit pound) and font color (in \"#rrggbb\" format)\n",
    "    bgcolor: in \"#rrggbb\" format\n",
    "    '''\n",
    "    def __init__(self, size, font, bgcolor, length = 4):\n",
    "        #todo: add param check and transform here\n",
    "        self.width, self.height = size\n",
    "        self.font_family, self.font_size, self.font_color = font\n",
    "        self.bgcolor = bgcolor\n",
    "        self.len = length\n",
    "        self.vocab = Vocab()\n",
    "        self.font = ImageFont.truetype(self.font_family, self.font_size)\n",
    "    def get_text(self):\n",
    "        return self.vocab.rand_string(self.len)\n",
    "    # by default, draw center align text\n",
    "    def draw_text(self, str):\n",
    "        dr = ImageDraw.Draw(self.im)\n",
    "        font_width, font_height = self.font.getsize(str)\n",
    "        # don't know why, but for center align, I should divide it by 2, other than 3\n",
    "        dr.text(((self.width - font_width) / 3, (self.height - font_height) / 3), str, fill = self.font_color, font = self.font)\n",
    "    def draw_background(self):\n",
    "        pass\n",
    "    def transform(self):\n",
    "        params = [1 - float(random.randint(1, 2)) / 100,\n",
    "                  0,\n",
    "                  0,\n",
    "                  0,\n",
    "                  1 - float(random.randint(1, 10)) / 100,\n",
    "                  float(random.randint(1, 2)) / 500,\n",
    "                  0.001,\n",
    "                  float(random.randint(1, 2)) / 500\n",
    "                  ]\n",
    "        self.im = self.im.transform((self.width, self.height), Image.PERSPECTIVE, params)\n",
    "    def filter(self):\n",
    "        self.im.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
    "    # by default, add no noises\n",
    "    def add_noise(self):\n",
    "        pass\n",
    "    def get_captcha(self):\n",
    "        self.im = Image.new(\"RGB\", (self.width, self.height), (self.bgcolor))\n",
    "        self.draw_background()\n",
    "        str = self.get_text()\n",
    "        self.draw_text(str)\n",
    "        #self.add_noise()\n",
    "        #dself.transform()\n",
    "        self.filter()\n",
    "        return self.im, str\n",
    "class JrttCaptcha(Captcha):\n",
    "    def __init__(self, size = (60, 25), font = (\"courbd.ttf\", 20, \"#0000ff\"), bgcolor = (255, 255, 255), dot_rate = 0.05):\n",
    "        Captcha.__init__(self, size, font, bgcolor)\n",
    "        self.dot_rate = dot_rate\n",
    "    def add_noise(self):\n",
    "        # add lines\n",
    "        nb_lines = random.randint(1, 2)\n",
    "        dr = ImageDraw.Draw(self.im)\n",
    "        for i in range(nb_lines):\n",
    "            # 避免begin和end太靠近，导致生成的干扰线太短\n",
    "            begin = (random.randint(0, self.width)/2, random.randint(0, self.height)/2)\n",
    "            end = (random.randint(self.width / 2, self.width), random.randint(0, self.height))\n",
    "            dr.line([begin, end], fill = (0, 0, 0))\n",
    "        # add dots\n",
    "        for w in range(self.width):\n",
    "            for h in range(self.height):\n",
    "                if random.randint(0, 100) / 100 <= self.dot_rate:\n",
    "                    dr.point((w, h), fill = (0, 0, 0))\n",
    "    def draw_text(self, str):\n",
    "        display_text = [\" \"] * (len(str) * 2 - 1)\n",
    "        for i in range(len(str)):\n",
    "            display_text[i * 2] = str[i]\n",
    "        super().draw_text(str)\n",
    "if __name__ == \"__main__\":\n",
    "    cap = JrttCaptcha()\n",
    "    #每调用一次，生成一个<图像,文本>对。其中图象可看成是输入，而文本可以看成是真值\n",
    "    img, text = cap.get_captcha()\n",
    "    img.save(text +\"_\" +str(random.randint(0,100)) + \".jpg\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.utils.data as tud\n",
    "import pdb\n",
    "import random\n",
    "import struct\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# def find_file_name(file_dir):#获取文件夹下所有文件名\n",
    "#     for root, dirs, files in os.walk(file_dir):\n",
    "#         return files\n",
    "# files_name = find_file_name('data')\n",
    "\n",
    "\n",
    "# for n in range(300):\n",
    "#     img = cv2.imread('data/'+files_name[n])\n",
    "#     for i in range(4):\n",
    "#         cropped = img[0:25, 15*(i):15*(i+1)]  # 裁剪坐标为[y0:y1, x0:x1]\n",
    "#         cv2.imwrite(\"data/one/\"+str(n)+\"_\"+str(i)+\"_\"+str(files_name[n][i])+\".jpg\", cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "def judge(img):\n",
    "    for i in range(15):\n",
    "        img[0][i] = 255\n",
    "        img[24][i] = 255\n",
    "    for i in range(25):\n",
    "        img[i][0] = 255\n",
    "        img[i][14] = 255\n",
    "    for x in range(23):\n",
    "        x = x+1\n",
    "        for y in range(13):\n",
    "            y = y+1\n",
    "            m = 0\n",
    "            if(0 == img[x-1][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x-1][y]):\n",
    "                m = m+1\n",
    "            if(0 == img[x-1][y+1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x][y+1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y+1]):\n",
    "                m = m+1\n",
    "            if m<3:\n",
    "                img[x][y] = 255\n",
    "    for x in range(23-1,-1,-1):\n",
    "        x = x+1\n",
    "        for y in range(13-1,-1,-1):\n",
    "            y = y+1\n",
    "            m = 0\n",
    "            if(0 == img[x-1][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x-1][y]):\n",
    "                m = m+1\n",
    "            if(0 == img[x-1][y+1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x][y+1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y-1]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y]):\n",
    "                m = m+1\n",
    "            if(0 == img[x+1][y+1]):\n",
    "                m = m+1\n",
    "            if m<3:\n",
    "                img[x][y] = 255\n",
    "    return img\n",
    "def find_file_name(file_dir):#获取文件夹下所有文件名\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        return files\n",
    "#全局阈值\n",
    "def threshold_demo(image):#二值化函数\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) #把输入图像灰度化\n",
    "    #直接阈值化是对输入的单通道矩阵逐像素进行阈值分割。\n",
    "#     ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_TRIANGLE)\n",
    "#     print(\"threshold value %s\"%ret)\n",
    "    binary = gray\n",
    "    return binary\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "files_name = find_file_name('data/one')#获取所有文件名\n",
    "# src = cv2.imread('data/one/'+files_name[0])\n",
    "CEL = True #CEL 代表CrossEntropyLoss 此loss方程需要需要的结果y和其他loss方程不一样（单维），所以需要另外处理\n",
    "add = [255 for i in range(125)]\n",
    "add = np.array(add)\n",
    "add = add.reshape(25,5)\n",
    "data_image = [[np.c_[add,judge(threshold_demo(cv2.imread('data/one/'+n))),add]] for n in files_name]#生成二值化之后的数据#其中做了judge，去噪，拼接矩阵#这一行非常复杂，需要理解很久\n",
    "data_lable = [n.split(\"_\")[2][0] for n in files_name]\n",
    "ind = \"123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "data_lable = [ind.index(n) for n in data_lable]#转换成数字标签\n",
    "datas = np.array(data_image) #datas的类型从list转换为numpy\n",
    "lable = np.array(data_lable) #lable的类型从list转换为numpy\n",
    "lable = lable.astype(np.int) #把lable里面数据强转为int\n",
    "datas = datas.astype(np.float32) #把atas里面数据强转为float32\n",
    "training_image = torch.from_numpy(datas) #把datas变成torch类型的矩阵(torch可以使用gpu)\n",
    "training_lable = torch.from_numpy(lable) #同理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101_3_4.jpg\n",
      "[1, 7, 11, 2, 12, 11, 5, 30, 12, 12, 4, 3, 12, 16, 22, 12, 12, 18, 19, 4, 12, 22, 10, 6, 12, 25, 33, 33, 12, 27, 32, 13, 12, 28, 15, 33, 12, 30, 11, 31, 12, 31, 27, 33, 2, 17, 26, 32, 13, 7, 18, 26, 13, 24, 30, 27, 13, 31, 2, 12, 14, 1, 14, 27, 14, 3, 14, 13, 14, 10, 24, 4, 14, 11, 33, 25, 14, 12, 9, 1, 14, 14, 6, 1, 14, 22, 31, 11, 2, 18, 25, 15, 14, 24, 10, 30, 14, 27, 1, 33, 14, 32, 30, 13, 14, 34, 27, 3, 15, 5, 26, 25, 15, 7, 18, 27, 15, 16, 32, 30, 15, 18, 3, 2, 15, 18, 19, 2, 15, 24, 24, 18, 2, 26, 12, 16, 15, 26, 10, 27, 16, 3, 7, 16, 16, 6, 13, 5, 16, 11, 34, 7, 16, 17, 28, 2, 16, 18, 15, 10, 16, 18, 15, 31, 16, 22, 3, 14, 16, 27, 16, 19, 16, 30, 25, 29, 3, 1, 1, 1, 17, 1, 15, 30, 17, 14, 13, 30, 17, 17, 24, 1, 17, 27, 9, 21, 17, 32, 32, 26, 17, 32, 32, 32, 18, 6, 2, 5, 18, 12, 10, 1, 18, 25, 16, 33, 19, 7, 18, 31, 3, 5, 4, 6, 19, 10, 14, 15, 19, 13, 30, 10, 19, 17, 17, 11, 19, 24, 6, 3, 19, 26, 30, 2, 19, 27, 14, 21, 19, 30, 1, 12, 19, 32, 14, 1, 21, 2, 31, 14, 21, 5, 4, 12, 3, 5, 7, 7, 21, 5, 4, 21, 21, 6, 16, 26, 21, 9, 2, 13, 21, 18, 4, 5, 22, 12, 12, 33, 22, 15, 15, 13, 22, 24, 3, 6, 22, 24, 34, 27, 22, 27, 10, 34, 22, 28, 1, 1, 3, 12, 13, 1, 22, 30, 16, 21, 24, 1, 24, 5, 24, 4, 28, 28, 24, 5, 21, 11, 24, 9, 2, 31, 24, 19, 9, 18, 24, 19, 27, 24, 24, 25, 27, 9, 24, 27, 12, 5, 24, 27, 29, 4, 3, 17, 8, 32, 24, 34, 27, 14, 25, 1, 29, 10, 25, 3, 22, 18, 25, 3, 34, 2, 25, 5, 8, 3, 25, 5, 12, 14, 25, 7, 30, 5, 25, 16, 18, 4, 25, 16, 27, 16, 25, 18, 14, 21, 3, 22, 3, 21, 25, 22, 14, 13, 25, 25, 13, 33, 25, 32, 4, 3, 26, 7, 3, 13, 26, 12, 7, 6, 26, 14, 7, 2, 26, 17, 12, 17, 26, 18, 34, 31, 26, 19, 12, 17, 26, 21, 2, 10, 3, 24, 27, 4, 1, 15, 1, 26, 26, 22, 5, 1, 26, 25, 17, 12, 26, 26, 21, 12, 26, 30, 28, 32, 26, 33, 34, 26, 27, 12, 4, 29, 27, 13, 2, 15, 27, 14, 7, 26, 27, 15, 11, 14, 27, 18, 33, 10, 3, 31, 13, 1, 27, 24, 3, 4, 27, 26, 21, 32, 27, 28, 30, 32, 28, 3, 9, 18, 28, 4, 34, 34, 28, 8, 7, 31, 28, 10, 25, 7, 28, 10, 26, 14, 28, 12, 4, 5, 28, 12, 33, 15, 4, 1, 33, 18, 28, 13, 22, 14, 28, 17, 22, 7, 28, 18, 4, 4, 28, 18, 28, 21, 28, 19, 5, 32, 28, 21, 18, 19, 28, 22, 17, 13, 28, 24, 6, 27, 28, 27, 1, 5, 28, 28, 1, 8, 4, 3, 28, 28, 28, 28, 32, 12, 29, 1, 5, 33, 29, 1, 13, 30, 29, 2, 6, 16, 29, 3, 3, 26, 29, 3, 26, 26, 29, 10, 5, 29, 29, 10, 15, 29, 29, 12, 31, 7, 29, 13, 21, 29, 4, 4, 8, 29, 29, 18, 17, 3, 29, 19, 10, 4, 29, 21, 16, 22, 29, 26, 22, 6, 29, 27, 24, 3, 29, 27, 33, 14, 29, 29, 32, 3, 29, 33, 15, 10, 30, 1, 15, 17, 30, 2, 7, 19, 4, 4, 33, 14, 30, 2, 34, 22, 30, 5, 6, 2, 30, 6, 25, 10, 30, 7, 19, 6, 30, 15, 16, 8, 30, 31, 8, 11, 31, 4, 1, 22, 31, 7, 29, 4, 31, 8, 9, 15, 31, 14, 4, 16, 4, 6, 25, 24, 31, 16, 1, 10, 31, 16, 3, 15, 31, 16, 19, 34, 31, 17, 14, 8, 31, 21, 5, 28, 31, 21, 33, 24, 31, 26, 33, 7, 31, 30, 3, 13, 31, 32, 34, 21, 32, 12, 21, 27, 4, 9, 29, 19, 32, 14, 6, 22, 32, 14, 26, 13, 32, 18, 12, 18, 32, 22, 6, 17, 32, 25, 5, 30, 32, 25, 32, 34, 32, 26, 21, 34, 32, 29, 33, 27, 32, 31, 13, 7, 32, 34, 13, 32, 4, 14, 29, 16, 33, 4, 34, 28, 33, 6, 10, 31, 33, 7, 16, 15, 33, 9, 30, 18, 33, 19, 30, 15, 33, 22, 5, 9, 33, 24, 31, 34, 33, 26, 32, 21, 33, 31, 16, 32, 33, 33, 4, 14, 4, 15, 8, 24, 34, 1, 1, 34, 34, 1, 34, 4, 34, 7, 11, 7, 34, 7, 29, 30, 34, 13, 16, 27, 34, 16, 14, 6, 34, 18, 16, 13, 34, 18, 31, 29, 34, 24, 5, 32, 34, 32, 24, 33, 4, 17, 9, 1, 1, 15, 3, 27, 4, 18, 22, 25, 4, 19, 34, 30, 4, 28, 10, 19, 5, 3, 10, 34, 5, 9, 9, 30, 5, 12, 7, 18, 5, 22, 6, 5, 5, 25, 12, 31, 5, 25, 15, 21, 5, 26, 2, 15, 1, 21, 24, 10, 5, 31, 7, 26, 6, 6, 22, 8, 6, 10, 2, 22, 6, 10, 17, 7, 6, 16, 27, 10, 7, 3, 17, 2, 7, 4, 26, 6, 7, 8, 21, 3, 7, 11, 34, 22, 7, 12, 15, 17, 1, 25, 4, 6, 7, 14, 24, 2, 7, 14, 25, 3, 7, 16, 29, 25, 7, 19, 31, 8, 7, 21, 7, 34, 7, 28, 17, 30, 7, 28, 24, 30, 7, 31, 2, 26, 7, 31, 12, 24, 7, 33, 14, 24, 1, 25, 32, 3, 7, 33, 27, 1, 8, 7, 13, 3, 8, 13, 6, 11, 8, 13, 14, 18, 8, 24, 24, 9, 8, 26, 14, 27, 8, 34, 21, 11, 9, 8, 22, 1, 9, 9, 31, 2, 9, 14, 21, 21, 1, 29, 22, 3, 9, 14, 21, 25, 9, 16, 13, 16, 9, 16, 24, 19, 9, 17, 1, 19, 9, 17, 10, 26, 9, 25, 28, 18, 9, 27, 3, 9, 9, 27, 33, 13, 9, 32, 27, 34, 9, 34, 8, 31, 2, 5, 11, 11, 10, 6, 25, 30, 10, 7, 12, 18, 10, 10, 3, 15, 10, 16, 15, 11, 10, 16, 34, 34, 10, 21, 22, 6, 10, 21, 32, 17, 10, 25, 9, 21, 10, 28, 13, 14, 10, 30, 11, 34, 2, 8, 16, 10, 10, 30, 34, 19, 10, 31, 1, 33, 10, 34, 4, 7, 11, 12, 26, 18, 11, 25, 27, 7, 11, 25, 27, 18, 11, 26, 8, 29, 11, 27, 18, 21, 11, 33, 7, 32, 11, 34, 34, 29, 2, 16, 8, 21]\n",
      "1200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "datas = np.array(data_image) #datas的类型从list转换为numpy\n",
    "m = 11\n",
    "print(files_name[m])\n",
    "print(data_lable)\n",
    "print(len(files_name))\n",
    "files_name_all = files_name[m].split(\"_\")\n",
    "# print(files_name_all[2][0])\n",
    "# add = [255 for i in range(125)]\n",
    "# add = np.array(add)\n",
    "# add = add.reshape(25,5)\n",
    "# result = np.c_[add,datas[m][0],add]\n",
    "# for n in datas:\n",
    "a = datas[m][0].reshape(25,25) #显示图片\n",
    "fig = plt.figure()\n",
    "plotwindow = fig.add_subplot(111)\n",
    "plt.imshow(a , cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [50,100,150,200,300]\n",
    "x = [80,97.5,91.6,93.75,99.17]\n",
    "plt.plot(y,x)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_demo(image):#二值化函数\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) #把输入图像灰度化\n",
    "    #直接阈值化是对输入的单通道矩阵逐像素进行阈值分割。\n",
    "    ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_TRIANGLE)\n",
    "#     print(\"threshold value %s\"%ret)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(len(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106_2_x.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'dst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-fa531a4048b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"123.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dst' is not defined"
     ]
    }
   ],
   "source": [
    "m = 30\n",
    "img = cv2.imread('data/one/'+files_name[m])\n",
    "# img = cv2.fastNlMeansDenoisingColored(img,None,20,20,7,21)\n",
    "img = threshold_demo(img)\n",
    "img = judge(img)\n",
    "print(files_name[m])\n",
    "a = img.reshape(25,15) #显示图片\n",
    "fig = plt.figure()\n",
    "plotwindow = fig.add_subplot(111)\n",
    "plt.imshow(a , cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(dst.shape)\n",
    "cv2.imwrite(\"123.png\", dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    " \n",
    "class ResidualBlock(nn.Module):\n",
    "    #实现子module: Residual    Block\n",
    "    def __init__(self,inchannel,outchannel,stride=1,shortcut=None):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.left=nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,3,stride,1,bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel,outchannel,3,1,1,bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        \n",
    "        self.right=shortcut\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.left(x)\n",
    "        residual=x if self.right is None else self.right(x)\n",
    "        out+=residual\n",
    "        return F.relu(out)\n",
    "    \n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    #实现主module:ResNet34\n",
    "    #ResNet34包含多个layer,每个layer又包含多个residual block\n",
    "    #用子module实现residual block , 用 _make_layer 函数实现layer\n",
    "    def __init__(self,num_classes=1000):\n",
    "        super(ResNet,self).__init__()\n",
    "        #重复的layer,分别有3,4,6,3个residual block\n",
    "        self.BN = nn.BatchNorm2d(1)\n",
    "#         48-3+1 = 46\n",
    "#         (46-3-1)/2 = 21\n",
    "#         (21-5-1)/2 = 21\n",
    "# torch.Size([64, 64, 25, 25])\n",
    "# torch.Size([64, 128, 13, 13])\n",
    "# torch.Size([64, 256, 7, 7])\n",
    "# torch.Size([64, 512, 4, 4])\n",
    "#         25-2+1 = 24\n",
    "#         (24-2)/2+1\n",
    "        self.layer1=self._make_layer(1,64,2)\n",
    "        self.layer2=self._make_layer(64,128,3,)\n",
    "        self.layer3=self._make_layer(128,256,2,stride=2)\n",
    "        self.layer4=self._make_layer(256,512,2,stride=2)\n",
    "        \n",
    "        #分类用的全连接\n",
    "        self.fc=nn.Linear(512,num_classes)\n",
    "        \n",
    "    def _make_layer(self,inchannel,outchannel,block_num,stride=1):\n",
    "        #构建layer,包含多个residual block\n",
    "        shortcut=nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,1,stride,bias=False),\n",
    "            nn.BatchNorm2d(outchannel))\n",
    " \n",
    "        layers=[ ]\n",
    "        layers.append(ResidualBlock(inchannel,outchannel,stride,shortcut))\n",
    "        \n",
    "        for i in range(1,block_num):\n",
    "            layers.append(ResidualBlock(outchannel,outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.BN(x)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=F.avg_pool2d(x,7)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1,20,2)\n",
    "\n",
    "#       25-2+1 = 24\n",
    "#       \n",
    "        #pooling\n",
    "#       5*5\n",
    "        self.conv2 = torch.nn.Conv2d(20,20,3)\n",
    "        self.linear1 = torch.nn.Linear(20*5*5,300)\n",
    "        self.linear5 = torch.nn.Linear(300,200)\n",
    "        self.linear6 = torch.nn.Linear(200,100)\n",
    "        self.linear7 = torch.nn.Linear(100,7)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         print(x[0][1])\n",
    "#         pdb.set_trace()\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1,20*5*5)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear5(x))\n",
    "        x = F.relu(self.linear6(x))\n",
    "        x = F.relu(self.linear7(x))\n",
    "#         print(F.softmax(x, dim = 1)) #调试语句\n",
    "#         pdb.set_trace()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionClassificationDataset(tud.Dataset): #定义数据读取类，此类用于读取数据，最为关键的函数是getitem（）\n",
    "    def __init__(self,training_image,training_lable, CEL): #此函数用于初始化\n",
    "        super(ExpressionClassificationDataset, self).__init__()\n",
    "        self.training_data = training_image.to(DEVICE)\n",
    "        if(CEL == True): #CEL 代表CrossEntropyLoss 此loss方程需要需要的结果y和其他loss方程不一样（单维），所以需要另外处理\n",
    "            self.training_lable = training_lable.to(DEVICE)\n",
    "        else:\n",
    "            self.training_lable = torch.zeros(len(training_lable),7,device = DEVICE)\n",
    "            for i in range(len(training_lable)):\n",
    "                self.training_lable[i][training_lable[i]] = 1\n",
    "        \n",
    "    def __len__(self): #此函数用于确定总数据大小，用于生成所有的bitch\n",
    "        return len(self.training_data)\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.training_data[idx]/255.,self.training_lable[idx]; #/255是把数据的大小限制在0-1之间，能极大减少学习的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接下来使用dataset将数据封装成batch(成组)\n",
    "#dataset类有三个重要函数，\n",
    "#__init__初始化 在创建此类的时候魂运行一次，用于将数据读入类中\n",
    "#__len__测量大小，用于和下面那个函数配合使用\n",
    "#__getitem__，此函数是dataset可以生成batch的关键函数，此函数的返回值代表取出一个数据。\n",
    "#则此类会成组的调用__getitem__来生成数据，把每一个返回值拼装成成组的数据\n",
    "#例如，batch_size设定为40，则此类就会成组的运行40次__getitem__来返回数据，每40次把数据合成一组\n",
    "#一共运行__len__返回值除以40次，也就是生成__len__返回值除以40组的数据\n",
    "class ExpressionClassificationDataset(tud.Dataset): #定义数据读取类，此类用于读取数据，最为关键的函数是getitem（）\n",
    "    def __init__(self,training_image,training_lable, CEL): #此函数用于初始化\n",
    "        super(ExpressionClassificationDataset, self).__init__()\n",
    "        self.training_data = training_image.to(DEVICE)\n",
    "        if(CEL == True): #CEL 代表CrossEntropyLoss 此loss方程需要需要的结果y和其他loss方程不一样（单维），所以需要另外处理\n",
    "            self.training_lable = training_lable.to(DEVICE)\n",
    "        else:\n",
    "            self.training_lable = torch.zeros(len(training_lable),7,device = DEVICE)\n",
    "            for i in range(len(training_lable)):\n",
    "                self.training_lable[i][training_lable[i]] = 1\n",
    "        \n",
    "    def __len__(self): #此函数用于确定总数据大小，用于生成所有的bitch\n",
    "        return len(self.training_data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.training_data[idx]/255.,self.training_lable[idx]; #/255是把数据的大小限制在0-1之间，能极大减少学习的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ExpressionClassificationDataset(training_image,training_lable,CEL = CEL)#用training_image和training_lable生成dataset类\n",
    "train_loader = tud.DataLoader(dataset,batch_size = 40, shuffle = False)#把数据提取成组,shuffle的意思是是否随机抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionClassification(object):\n",
    "    def __init__(self,training_image,training_lable,eta,batch_size,shuffle,CEL,model = None): #CEL 代表使用交叉熵计算loss\n",
    "        self.CEL = CEL\n",
    "        self.dataset = ExpressionClassificationDataset(training_image,training_lable,CEL = self.CEL)\n",
    "        self.split_9_1(len(training_image),batch_size) #把数据分为训练集和测试集  详细过程见下面的那个split函数\n",
    "        self.dataloader = tud.DataLoader(self.dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        if(None != model):\n",
    "            self.model = torch.load(model,map_location='cpu')\n",
    "        else:\n",
    "            if torch.cuda.is_available():\n",
    "                self.model = ResNet(35).cuda()  #定义模型类\n",
    "            else:\n",
    "                self.model = ResNet(35)\n",
    "        if (CEL == True):\n",
    "            self.loss_fn = torch.nn.CrossEntropyLoss() #定义loss_fn，loss方程\n",
    "        else:\n",
    "            self.loss_fn = torch.nn.MSELoss() #定义loss_fn，loss方程\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr = eta)#定义参数更新方式\n",
    "    def train(self): #开始训练\n",
    "        for e in range(NUM_EPOCHS): #每一个epochs\n",
    "            for i,(x,y) in enumerate (self.train_loader): #从dataloader中取出bitch数据进行训练\n",
    "#                 a = x[0].reshape(28,28) #显示图片\n",
    "#                 fig = plt.figure()\n",
    "#                 plotwindow = fig.add_subplot(111)\n",
    "#                 plt.imshow(a , cmap='gray')\n",
    "#                 plt.show()\n",
    "#                 print(y[0])\n",
    "                y_pred = self.model.forward(x)  #前项传播\n",
    "                \n",
    "                \n",
    "                if self.CEL == True:\n",
    "                    self.loss = self.loss_fn(y_pred,y.long()) #计算loss\n",
    "                else:\n",
    "                    self.loss = self.loss_fn(y_pred,y) #计算loss\n",
    "#                 if(i % 5 ==0):\n",
    "#                     print(y_pred)\n",
    "# #                 print(self.loss)\n",
    "#                 print(self.loss)\n",
    "                self.optimizer.zero_grad() #参数更新器重置为0\n",
    "                self.loss.backward()   # 反向传播\n",
    "                self.optimizer.step() #参数更新\n",
    "                \n",
    "            print(e,\":轮，loss = \",self.loss.item())\n",
    "            accuracy = self.test()\n",
    "            if e >= 100 and accuracy.item() >= 0.9:\n",
    "              print(\"准确率到90，保存模型\")\n",
    "              torch.save(self.model,\"model.pth\")\n",
    "            print(\"准确率为：\",accuracy);\n",
    "    def test(self): #测试函数\n",
    "        total_correct = 0.0\n",
    "        for i, (x,y) in enumerate(self.test_loader):\n",
    "            y_pred = self.model.forward(x)  #前项传播\n",
    "            if self.CEL == True:  #对于不同loss方程的处理\n",
    "                correct = self.correct_count_CEL(y,y_pred)\n",
    "            else:\n",
    "                correct = self.correct_count_MSE(y,y_pred)\n",
    "\n",
    "            total_correct = total_correct+correct\n",
    "#             pdb.set_trace()\n",
    "        \n",
    "        return total_correct/self.test_number\n",
    "    def correct_count_MSE(self,y,y_pred): #MES正确预测数量函数\n",
    "        return sum(a[torch.argmax(b)] == 1 for a, b in zip(y,y_pred))\n",
    "    def correct_count_CEL(self,y,y_pred): #CrossEntropyLoss正确预测数量函数\n",
    "        return sum(a == torch.argmax(b) for a, b in zip(y,y_pred))\n",
    "    def split_9_1(self,n_train,batch_size):\n",
    "        split = n_train // 10   #整数除法，要把数据分成9:1的训练集和测试集\n",
    "        self.test_number = split  #测试集总数\n",
    "        indices = list(range(n_train))\n",
    "        train_sampler = tud.sampler.SubsetRandomSampler(indices[split:])  #设置采样器\n",
    "        test_sampler = tud.sampler.SubsetRandomSampler(indices[:split])\n",
    "        self.train_loader = tud.DataLoader(self.dataset, sampler=train_sampler,batch_size = batch_size, shuffle=False)#利用采样的方法进行提取\n",
    "        self.test_loader = tud.DataLoader(self.dataset, sampler=test_sampler, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9500)\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 300\n",
    "EC = ExpressionClassification(training_image,training_lable,eta = 0.005,batch_size = 32,shuffle = True,CEL = True,model = \"model.pth\")\n",
    "print(EC.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9583)\n"
     ]
    }
   ],
   "source": [
    "print(EC.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
